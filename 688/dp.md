# 马的棋盘DP

记$f_{p,k}$为马在点$p$，还能移动$k$步，最终仍留在棋盘内的概率。

记$p = (x, y)$，$\text{n}(p)$为从$p$点移动一步可到达的点的集合，且$|\text{n}(p)| = 8$。

于是，不难倒推出状态转移方程如下：

$$
f_{p, k} = \frac{1}{8}\sum_{p' \in \text{n}(p)} f_{p', k - 1}
$$

- 对任意在棋盘外的$p'$，都有$f_{p', k} = 0$。这是因为一旦到达棋盘外，就不会再有返回棋盘内的机会了。
- 另一个初始条件是，对任意在棋盘内的$p'$，都有$f_{p', 0} = 1$。

实际做题时，如果$p'$在棋盘外，则可以认为其对DP计算中的加法没有贡献，直接跳过即可。

### 该DP做法的缺点

该DP做法会给出棋盘中的**所有点**作为马的起始点，在$k$步后，最终仍留在棋盘中的概率。但对于单一点的查询，可能根本不需要计算那么多点的$f_{p,k}$（因为棋子可能根本过不去）。

而记忆化搜索能够解决此问题。换言之，记忆化搜索进行了一些剪枝——虽然时空复杂度的上界与DP是一样的。

### 记忆化搜索

记忆化搜索的思路来源于某种暴力搜索。

最暴力的搜索：枚举所有可能的$k$步随机移动，结果一旦到达棋盘外则提前结束枚举，并更新“到达棋盘外的方案数”变量 `n_cnt`；同时，在$k$步后如果还留在棋盘内，则更新“仍留在棋盘内的方案数”`y_cnt`。最终结果为 `n_cnt / (n_cnt + y_cnt)`。

这个最暴力的搜索没办法改造成记忆化搜索。呵呵。

下面我们考虑一个能改造成记忆化搜索的暴力搜索。

记 `dfs()`函数接收点$p$和步数$k$，返回马在点$p$，还能移动$k$步，最终仍留在棋盘内的概率。思路与DP一模一样，可以写出这样的代码：

```java
class Solution {
    public double knightProbability(int n, int k, int row, int column) {
        // 记忆化搜索
        double[][][] memo = new double[n][n][k + 1];
        return dfs(n, k, row, column, memo);
    }
    public double dfs(int n, int k, int i, int j, double[][][] memo) {
        // 走出边界了，这条路不通，概率为0
        if (i < 0 || j < 0 || i >= n || j >= n) {
            return 0;
        }
        // k 步走完了还没超出边界，这一步的概率是1，还需要乘上前面的 k 个 1/8
        if (k == 0) {
            return 1;
        }

        // 缓存中存在，直接返回
        if (memo[i][j][k] != 0) {
            return memo[i][j][k];
        }

        // 每一个方向的概率都是 1/8
        double ans = 0;
        for (final int[] dir : DIRS) {
            ans += dfs(n, k - 1, i + dir[0], j + dir[1], memo) / 8.0;
        }
        memo[i][j][k] = ans;

        return ans;
    }
}
```

可见，该方法进行了剪枝（只从起始点 `(row, column)`出发搜索），因此效率高于DP。
